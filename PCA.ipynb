{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning Using Grid Search With Parallel Computing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "import joblib\n",
    "import threading\n",
    "import multiprocessing\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(xmin,xmax,Delta,noise):\n",
    "    # Calculate f=sin(x1)+cos(x2)\n",
    "    x1 = np.arange(xmin,xmax+Delta,Delta)   # generate x1 values from xmin to xmax\n",
    "    x2 = np.arange(xmin,xmax+Delta,Delta)   # generate x2 values from xmin to xmax\n",
    "    x1, x2 = np.meshgrid(x1,x2)             # make x1,x2 grid of points\n",
    "    f = np.sin(x1) + np.cos(x2)             # calculate for all (x1,x2) grid\n",
    "    # Add random noise to f\n",
    "    random.seed(2020)                       # set random seed for reproducibility\n",
    "    for i in range(len(f)):\n",
    "        for j in range(len(f[0])):\n",
    "            f[i][j] = f[i][j] + random.uniform(-noise,noise)  # add random noise to f(x1,x2)\n",
    "\n",
    "    # Calculate and print the number of records\n",
    "    num_records = x1.size  # size of the grid (number of points)\n",
    "    print(f\"Number of records generated: {num_records}\")\n",
    "    return x1,x2,f\n",
    "\n",
    "# Create {x1,x2,f} dataset every 1.0 from -10 to 10, with a noise of +/- 0.5\n",
    "x1,x2,f=generate_data(-10,10,0.4,0.5) # Changed delta to generate different number of records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare Data for Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(x1,x2,f):\n",
    "    X = []\n",
    "    for i in range(len(f)):\n",
    "        for j in range(len(f)):\n",
    "            X_term = []\n",
    "            X_term.append(x1[i][j])\n",
    "            X_term.append(x2[i][j])\n",
    "            X.append(X_term)\n",
    "    y=f.flatten()\n",
    "    X=np.array(X)\n",
    "    y=np.array(y)\n",
    "    return X,y\n",
    "\n",
    "# Prepare X and y\n",
    "X,y = prepare_data(x1,x2,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kernel Ridge Regression (KRR) with Cross-Validation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*BASELINE*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KRR_function(X,y):\n",
    "    # Initialize lists with final results\n",
    "    y_pred_total = []\n",
    "    y_test_total = []\n",
    "    # Split data into test and train: random state fixed for reproducibility\n",
    "    kf = KFold(n_splits=10,shuffle=True,random_state=2020)\n",
    "    # kf-fold cross-validation loop\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        # Scale X_train and X_test\n",
    "        scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "        X_train_scaled = scaler.transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        # Fit KRR with (X_train_scaled, y_train), and predict X_test_scaled\n",
    "        KRR = KernelRidge()\n",
    "        y_pred = KRR.fit(X_train_scaled, y_train).predict(X_test_scaled)\n",
    "        # Append y_pred and y_test values of this k-fold step to list with total values\n",
    "        y_pred_total.append(y_pred)\n",
    "        y_test_total.append(y_test)\n",
    "    # Flatten lists with test and predicted values\n",
    "    y_pred_total = [item for sublist in y_pred_total for item in sublist]\n",
    "    y_test_total = [item for sublist in y_test_total for item in sublist]\n",
    "    # Calculate error metric of test and predicted values: rmse\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_total, y_pred_total))\n",
    "    return rmse\n",
    "KRR_function(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hyperparameter Grid Search for KRR*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KRR_function(hyperparams,X,y):\n",
    "    # Assign hyper-parameters\n",
    "    alpha_value,gamma_value = hyperparams\n",
    "    # Initialize lists with final results\n",
    "    y_pred_total = []\n",
    "    y_test_total = []\n",
    "    # Split data into test and train: random state fixed for reproducibility\n",
    "    kf = KFold(n_splits=10,shuffle=True,random_state=2020)\n",
    "    # kf-fold cross-validation loop\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        # Scale X_train and X_test\n",
    "        scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "        X_train_scaled = scaler.transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        # Fit KRR with (X_train_scaled, y_train), and predict X_test_scaled\n",
    "        KRR = KernelRidge(kernel='rbf',alpha=alpha_value,gamma=gamma_value)\n",
    "        y_pred = KRR.fit(X_train_scaled, y_train).predict(X_test_scaled)\n",
    "        # Append y_pred and y_test values of this k-fold step to list with total values\n",
    "        y_pred_total.append(y_pred)\n",
    "        y_test_total.append(y_test)\n",
    "    # Flatten lists with test and predicted values\n",
    "    y_pred_total = [item for sublist in y_pred_total for item in sublist]\n",
    "    y_test_total = [item for sublist in y_test_total for item in sublist]\n",
    "    # Calculate error metric of test and predicted values: rmse\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_total, y_pred_total))\n",
    "    print('KRR k-fold cross-validation . alpha: %7.6f, gamma: %7.4f, RMSE: %7.4f' %(alpha_value,gamma_value,rmse))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sequential Code Benchmarking**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_x = []\n",
    "graph_y = []\n",
    "graph_z = []\n",
    "\n",
    "counter = 0\n",
    "\n",
    "def create_hyperparams_grid(X,y):\n",
    "    global counter\n",
    "    for alpha_value in np.arange(-5.0,2.0,0.7):\n",
    "        alpha_value = pow(10,alpha_value)\n",
    "        graph_x_row = []\n",
    "        graph_y_row = []\n",
    "        graph_z_row = []\n",
    "        for gamma_value in np.arange(0.0,20,2):\n",
    "            counter += 1\n",
    "            print(f\"Task {counter} is running\")\n",
    "            hyperparams = (alpha_value,gamma_value)\n",
    "            rmse = KRR_function(hyperparams,X,y)\n",
    "            graph_x_row.append(alpha_value)\n",
    "            graph_y_row.append(gamma_value)\n",
    "            graph_z_row.append(rmse)\n",
    "        graph_x.append(graph_x_row)\n",
    "        graph_y.append(graph_y_row)\n",
    "        graph_z.append(graph_z_row)\n",
    "\n",
    "start = time.time()\n",
    "create_hyperparams_grid(X,y)\n",
    "end = time.time()\n",
    "print(\"Execution time:\", end-start)\n",
    "print(\"Value of counter:\", counter)\n",
    "\n",
    "graph_x=np.array(graph_x)\n",
    "graph_y=np.array(graph_y)\n",
    "graph_z=np.array(graph_z)\n",
    "min_z=np.min(graph_z)\n",
    "pos_min_z=np.argwhere(graph_z == np.min(graph_z))[0]\n",
    "print('Minimum RMSE: %.4f' %(min_z))\n",
    "print('Optimum alpha: %f' %(graph_x[pos_min_z[0],pos_min_z[1]]))\n",
    "print('Optimum gamma: %f' %(graph_y[pos_min_z[0],pos_min_z[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parallel Code Benchmarking**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Parallelizes the sequential section with - lock -*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Multithreading approach:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "lock = threading.Lock()\n",
    "graph_x = []\n",
    "graph_y = []\n",
    "graph_z = []\n",
    "counter = 0\n",
    "alpha_values = np.arange(-5.0,2.0,0.7)\n",
    "gamma_values = np.arange(0.0,20,2)\n",
    "\n",
    "def func_for_alpha_loop(alpha_value):\n",
    "    global counter\n",
    "    alpha_value = pow(10,alpha_value)\n",
    "    graph_x_row = []\n",
    "    graph_y_row = []\n",
    "    graph_z_row = []\n",
    "    for gamma_value in gamma_values:\n",
    "        with lock:\n",
    "            counter = counter + 1\n",
    "        print(f\"Task {counter} is running in thread {threading.get_ident()}\")\n",
    "        print(f\"Task {counter} is running in process {os.getpid()}\")\n",
    "        hyperparams = (alpha_value,gamma_value)\n",
    "        rmse = KRR_function(hyperparams,X,y)\n",
    "        graph_x_row.append(alpha_value)\n",
    "        graph_y_row.append(gamma_value)\n",
    "        graph_z_row.append(rmse)\n",
    "    with lock:\n",
    "        graph_x.append(graph_x_row)\n",
    "        graph_y.append(graph_y_row)\n",
    "        graph_z.append(graph_z_row)\n",
    "    \n",
    "start = time.time() \n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:\n",
    "    executor.map(func_for_alpha_loop, alpha_values) \n",
    "end = time.time()\n",
    "print(\"Execution time:\", end-start)\n",
    "print(\"Value of counter: \", counter)\n",
    "\n",
    "graph_x=np.array(graph_x)\n",
    "graph_y=np.array(graph_y)\n",
    "graph_z=np.array(graph_z)\n",
    "min_z=np.min(graph_z)\n",
    "pos_min_z=np.argwhere(graph_z == np.min(graph_z))[0]\n",
    "\n",
    "print('Minimum RMSE: %.4f' %(min_z))\n",
    "print('Optimum alpha: %f' %(graph_x[pos_min_z[0],pos_min_z[1]]))\n",
    "print('Optimum gamma: %f' %(graph_y[pos_min_z[0],pos_min_z[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Multiprocessing approach:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = multiprocessing.Manager()\n",
    "counter = manager.Value('i', 0)\n",
    "lock = manager.Lock()\n",
    "graph_x = manager.list()\n",
    "graph_y = manager.list()\n",
    "graph_z = manager.list()\n",
    "alpha_values = np.arange(-5.0,2.0,0.7)\n",
    "gamma_values = np.arange(0.0,20,2)\n",
    "\n",
    "def func_for_alpha_loop(alpha_value):  \n",
    "    alpha_value = pow(10,alpha_value)\n",
    "    graph_x_row = []\n",
    "    graph_y_row = []\n",
    "    graph_z_row = []\n",
    "    for gamma_value in gamma_values:\n",
    "        hyperparams = (alpha_value,gamma_value)\n",
    "        rmse = KRR_function(hyperparams,X,y)\n",
    "        with lock:\n",
    "            counter.value = counter.value + 1 \n",
    "        print(f\"Task {counter.value} is running in process {os.getpid()}\")\n",
    "        graph_x_row.append(alpha_value)\n",
    "        graph_y_row.append(gamma_value)\n",
    "        graph_z_row.append(rmse)\n",
    "    with lock:\n",
    "        graph_x.append(graph_x_row)\n",
    "        graph_y.append(graph_y_row)\n",
    "        graph_z.append(graph_z_row)\n",
    "\n",
    "start = time.time()\n",
    "joblib.Parallel(n_jobs=8)(joblib.delayed(func_for_alpha_loop)(alpha_value) for alpha_value in alpha_values)\n",
    "end = time.time()\n",
    "print(\"Execution time:\", end-start)\n",
    "print(\"counter: \", counter.value)\n",
    "\n",
    "graph_x=np.array(graph_x)\n",
    "graph_y=np.array(graph_y)\n",
    "graph_z=np.array(graph_z)\n",
    "min_z=np.min(graph_z)\n",
    "pos_min_z=np.argwhere(graph_z == np.min(graph_z))[0]\n",
    "print('Minimum RMSE: %.4f' %(min_z))\n",
    "print('Optimum alpha: %f' %(graph_x[pos_min_z[0],pos_min_z[1]]))\n",
    "print('Optimum gamma: %f' %(graph_y[pos_min_z[0],pos_min_z[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References:**\n",
    "\n",
    "- https://towardsdatascience.com/grid-search-in-python-from-scratch-hyperparameter-tuning-3cca8443727b\n",
    "\n",
    "- https://joblib.readthedocs.io/en/stable/parallel.html\n",
    "\n",
    "- https://realpython.com/intro-to-python-threading/\n",
    "\n",
    "- https://superfastpython.com/thread-safe-write-to-file-in-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
